{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20317052",
   "metadata": {},
   "source": [
    "# Customized Convolutional Neural Network Hyperparameters Sampling on MNIST Dataset\n",
    "- Show network architectures (optimization + Hyperparameter tunning)\n",
    "- Basically Hyperparameters tunning\n",
    "- Applied Dataset Normalization Techniques\n",
    "- Analysis with integrated Tensorboard and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7f8ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nguye\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.33.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efc66289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\nguye\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (2.25.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (1.33.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (52.0.0.post20210125)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (1.34.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (3.17.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (1.19.5)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (0.36.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from tensorboard) (0.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd08a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import simplejson as json\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeec396",
   "metadata": {},
   "source": [
    "### Non Batch Normalization Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5593bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomedNetwork(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Class to create customized network (this is determined by the user)\n",
    "class CustomedNetwork(nn.Module):\n",
    "    # CONSTRUCTOR\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize 5 distinct layers of the network for building forward step\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5, stride=1)\n",
    "        \n",
    "        # Fully connection layers\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features=60, bias=True)\n",
    "        self.out = nn.Linear(in_features = 60, out_features=10, bias=True) \n",
    "    \n",
    "    # PUBLIC METHOD\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward propagation of the Customed Neural Network\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x:\n",
    "            input batch of images\n",
    "        \"\"\"\n",
    "        # Input layers\n",
    "        x = x\n",
    "        \n",
    "        # Convolution layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Convolution layer 2 \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Process input from convolution input to 1 input for fully connected layer\n",
    "        x = x.reshape(-1, 12*4*4)\n",
    "        \n",
    "        # Linear layer 1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Linear layer 2\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "customed_net = CustomedNetwork()\n",
    "print(customed_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c932b09",
   "metadata": {},
   "source": [
    "### Batch Normalzation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd6b308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (4): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Flatten(start_dim=1, end_dim=-1)\n",
      "  (8): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (9): ReLU()\n",
      "  (10): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (12): ReLU()\n",
      "  (13): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_norm_network = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.BatchNorm2d(6), # batch norm\n",
    "    nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features=12*4*4, out_features=120),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(120), # batch norm 1 d since we already flatten out our images\n",
    "    nn.Linear(in_features=120, out_features=60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=60, out_features=10)\n",
    ")\n",
    "\n",
    "print(batch_norm_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6803073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to create an object to run the surveying parameters lists combinations\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        \"\"\"Get the lists of parameters' values \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        params:\n",
    "            list of parameters contained of different related parameters\n",
    "        \"\"\"\n",
    "        Run = namedtuple(\"Run\", params.keys())\n",
    "        \n",
    "        runs_list = []\n",
    "        \n",
    "        for value in product(*params.values()):\n",
    "            runs_list.append(Run(*value))\n",
    "            \n",
    "        return runs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9086270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Run Manage that run the surveys of combinations of values of the RunBuilder() object\n",
    "class RunManager():\n",
    "    # CONSTRUCTORS\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize parameters\n",
    "        \"\"\"\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0;\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None # Tensorboard\n",
    "    \n",
    "    # PUBLIC METHODS    \n",
    "    def begin_run(self, run, network, loaders):\n",
    "        \"\"\"Start running the values combinations surveys\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        run:\n",
    "            run list\n",
    "        network:\n",
    "            neural network\n",
    "        loader:\n",
    "            DataLoader - basically preprocessed data objects\n",
    "        \"\"\"\n",
    "        self.run_start_time = time.time() # used for keep track of run time\n",
    "        \n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f\"-{run}\")\n",
    "        \n",
    "        images, labels = next(iter(self.loader)) # get the first batch of images and labels\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image(\"image\", grid)\n",
    "        \n",
    "        # Try CUDA\n",
    "        self.tb.add_graph(self.network, images.to(getattr(run, \"device\", \"cpu\")))   \n",
    "        \n",
    "    def end_run(self):\n",
    "        \"\"\"End runningthe values combinations surveys\n",
    "        \"\"\"\n",
    "        self.tb.close() # close tensorboard\n",
    "        self.epoch_count = 0 # reinitialized the epoch\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        \"\"\"Begin the epoch, initialize related variables\n",
    "        \"\"\"\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        \"\"\"End the epoch, calculated initialized variables above \n",
    "        \"\"\"\n",
    "        # Calculate run time\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "        \n",
    "        # Calculate the loss and accuracy of the trained dataset\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "        \n",
    "        # Calculate the average loss and accuracy\n",
    "        self.tb.add_scalar(\"Loss\", loss, self.epoch_count)\n",
    "        self.tb.add_scalar(\"Accuracy\", accuracy, self.epoch_count)\n",
    "        \n",
    "        # Draw historgram \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f\"{name}.grad\", param.grad, self.epoch_count)\n",
    "            \n",
    "        # Build pandas to data output of tensorboard\n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results[\"loss\"] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results[\"epoch duration\"] = epoch_duration\n",
    "        results[\"run duration\"] = run_duration\n",
    "        \n",
    "        # Add data in the DataFrames\n",
    "        for k,v in self.run_params._asdict().items(): \n",
    "            results[k] = v # allow us to see what results match with what param\n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient=\"columns\")\n",
    "        \n",
    "        # Update Dataframe in .ipynb in real time\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "    \n",
    "    def track_loss(self, loss):\n",
    "        \"\"\"Track the loss\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        loss:\n",
    "            loss of the training process of a batch\n",
    "        \"\"\"\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "        \n",
    "    def track_num_correct(self, preds, labels):\n",
    "        \"\"\"Track total number of correct of a batch\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        preds:\n",
    "            list of predictions in training process\n",
    "        labels:\n",
    "            list of labels given in the dataset\n",
    "        \"\"\"\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "        \n",
    "    def save(self, file_name):\n",
    "        \"\"\"Save the Dataframe to .csv file\n",
    "        \"\"\"\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data,\n",
    "            orient=\"columns\"\n",
    "        ).to_csv(f\"{file_name}.csv\") # save in csv\n",
    "        \n",
    "        # to create in tensorboard \n",
    "        with open(f\"{file_name}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent = 4)\n",
    "        \n",
    "    # PRIVATE METHODS\n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        \"\"\"Get the total number that the prediction is correct with the labels\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        preds:\n",
    "            list of predictions\n",
    "        labels:\n",
    "            list of labels\n",
    "\n",
    "        Return\n",
    "        ----------\n",
    "        total number that prediction and label are equal when comparing 2 lists\n",
    "        \"\"\"\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e730628c",
   "metadata": {},
   "source": [
    "## Get Dataset - MNIST\n",
    "- Normalization: Standardization is a specific type of normalization technique and sometime is referred to as z-score normalization or the standard score.\n",
    "    - z = (x-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b8b2d1",
   "metadata": {},
   "source": [
    "### Download Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64683d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.MNIST(\n",
    "    root=\"./data/MNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([ # convert image to \n",
    "        transforms.ToTensor()\n",
    "    ]))\n",
    "print(train_set.data.size())\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root=\"./data/MNIST\", \n",
    "    train = False, \n",
    "    transform=transforms.Compose([ # convert image to \n",
    "        transforms.ToTensor()\n",
    "    ]))\n",
    "print(test_set.data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a27c6",
   "metadata": {},
   "source": [
    "### Calculate the mean and standard of deviation for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a060104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1307)\n",
      "tensor(0.3081)\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(train_set, batch_size=1000, num_workers=1) # create dataloader\n",
    "num_of_pixels = len(train_set) * 28 * 28 # number of total pixel in the image, 28x28 = height and width of the image\n",
    "\n",
    "# Mean\n",
    "total_sum = 0 \n",
    "for batch in loader: total_sum += batch[0].sum() # total sum of all pixel in 1 image\n",
    "mean = total_sum / num_of_pixels\n",
    "\n",
    "# Standard of Dev\n",
    "sum_of_squared_error = 0\n",
    "for batch in loader: sum_of_squared_error += ((batch[0]-mean).pow(2)).sum()\n",
    "std = torch.sqrt(sum_of_squared_error / num_of_pixels)\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81316c2",
   "metadata": {},
   "source": [
    "### Create a new normalized MNIST processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f683dd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "train_set_normal = torchvision.datasets.MNIST(\n",
    "    root=\"./data/MNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    ")\n",
    "print(train_set_normal.data.size())\n",
    "\n",
    "test_set_normal = torchvision.datasets.MNIST(\n",
    "    root=\"./data/MNIST\", \n",
    "    train = False, \n",
    "    transform=transforms.Compose([ # convert image to \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]))\n",
    "print(test_set_normal.data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80adcf",
   "metadata": {},
   "source": [
    "### Create a DataLoader and analyse the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6720ef43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.1284e-08), tensor(1.))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(train_set_normal, batch_size=len(train_set), num_workers=1)\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e76d156",
   "metadata": {},
   "source": [
    "### Create trainsets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f1c45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets = {\n",
    "    'not_normal': train_set,\n",
    "    'normal': train_set_normal\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e850e",
   "metadata": {},
   "source": [
    "### Create networks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0752fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "customed_network = CustomedNetwork()# allow to try CUDA\n",
    "\n",
    "networks  = {\n",
    "    'no_batch_norm_net': customed_network,\n",
    "    'batch_norm_net': batch_norm_network\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc562666",
   "metadata": {},
   "source": [
    "### Training & Testing Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "800f3087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>device</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.481577</td>\n",
       "      <td>0.992417</td>\n",
       "      <td>28.928096</td>\n",
       "      <td>147.617012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.081974</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>27.011807</td>\n",
       "      <td>174.878378</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263599</td>\n",
       "      <td>0.993200</td>\n",
       "      <td>29.295499</td>\n",
       "      <td>99.482012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.922963</td>\n",
       "      <td>0.995017</td>\n",
       "      <td>28.016947</td>\n",
       "      <td>127.987806</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.454989</td>\n",
       "      <td>0.991833</td>\n",
       "      <td>33.790269</td>\n",
       "      <td>98.908297</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.744353</td>\n",
       "      <td>0.996300</td>\n",
       "      <td>31.787043</td>\n",
       "      <td>131.156647</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.077831</td>\n",
       "      <td>0.994183</td>\n",
       "      <td>32.442022</td>\n",
       "      <td>96.841218</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.763967</td>\n",
       "      <td>0.995767</td>\n",
       "      <td>33.016057</td>\n",
       "      <td>130.183293</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0    1      1  1.481577  0.992417       28.928096    147.617012  0.01   \n",
       "1    1      2  1.081974  0.993983       27.011807    174.878378  0.01   \n",
       "2    2      1  1.263599  0.993200       29.295499     99.482012  0.01   \n",
       "3    2      2  0.922963  0.995017       28.016947    127.987806  0.01   \n",
       "4    3      1  2.454989  0.991833       33.790269     98.908297  0.01   \n",
       "5    3      2  0.744353  0.996300       31.787043    131.156647  0.01   \n",
       "6    4      1  1.077831  0.994183       32.442022     96.841218  0.01   \n",
       "7    4      2  0.763967  0.995767       33.016057    130.183293  0.01   \n",
       "\n",
       "   batch_size  num_workers  shuffle device    trainset            network  \\\n",
       "0        1000            0     True    cpu  not_normal  no_batch_norm_net   \n",
       "1        1000            0     True    cpu  not_normal  no_batch_norm_net   \n",
       "2        1000            0     True    cpu  not_normal     batch_norm_net   \n",
       "3        1000            0     True    cpu  not_normal     batch_norm_net   \n",
       "4        1000            0     True    cpu      normal  no_batch_norm_net   \n",
       "5        1000            0     True    cpu      normal  no_batch_norm_net   \n",
       "6        1000            0     True    cpu      normal     batch_norm_net   \n",
       "7        1000            0     True    cpu      normal     batch_norm_net   \n",
       "\n",
       "   num_epochs  test_accuracy  \n",
       "0           2              0  \n",
       "1           2              0  \n",
       "2           2              0  \n",
       "3           2              0  \n",
       "4           2              0  \n",
       "5           2              0  \n",
       "6           2              0  \n",
       "7           2              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the normalized-dataset model on the 10000 test images: 0.60\n"
     ]
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [0.01, 0.02, 0.03],\n",
    "    batch_size = [1000],\n",
    "    num_workers = [0],\n",
    "    shuffle = [True],\n",
    "    device = ['cpu'],\n",
    "    trainset = ['not_normal', 'normal'],\n",
    "    network = list(networks.keys()),\n",
    "    num_epochs = [2],\n",
    "    test_accuracy = [0]\n",
    ")\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    params['test_accuracy'] = 0 # restart writing test_accuracy\n",
    "    \n",
    "    device = torch.device(run.device) # allow to try CUDA\n",
    "    network = networks[run.network].to(device) # allow to try CUDA\n",
    "    \n",
    "    network.train() # mark network as train\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(trainsets[run.trainset], batch_size=run.batch_size, shuffle=run.shuffle, num_workers=run.num_workers) # num worker to speed up process for dataloader\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    m.begin_run(run, network, train_loader)\n",
    "    for epoch in range(run.num_epochs):\n",
    "        m.begin_epoch()\n",
    "        for batch in train_loader:\n",
    "            images = batch[0].to(device) # allow to try CUDA\n",
    "            labels = batch[1].to(device) # allow to try CUDA\n",
    "            preds = network(images) # pass batch\n",
    "            loss = F.cross_entropy(preds, labels) # calculate loss\n",
    "            optimizer.zero_grad() # zero gradient\n",
    "            loss.backward() # back prop for calculating gradient\n",
    "            optimizer.step() # update weights\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        \n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "    \n",
    "    if(run.trainset == 'not_normal'):\n",
    "        # Get the testing dataset\n",
    "        test_loader = torch.utils.data.DataLoader(test_set, batch_size=run.batch_size, shuffle=run.shuffle, num_workers=run.num_workers)\n",
    "        \n",
    "        network.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                images = batch[0].to(device) # allow to try CUDA\n",
    "                labels = batch[1].to(device) # allow to try CUDA\n",
    "                preds = network(images) # pass batch\n",
    "                accuracy = (preds.argmax(dim=1).eq(labels).sum().item()) / float(run.batch_size)\n",
    "        print('Test Accuracy of the not-normalized-dataset model on the 10000 test images: %.2f' % accuracy)\n",
    "#         params['test_accuracy'] = accuracy\n",
    "        \n",
    "    elif(run.trainset == \"normal\"):\n",
    "        # Get the testing dataset\n",
    "        test_loader_normal = torch.utils.data.DataLoader(test_set_normal, batch_size=run.batch_size, shuffle=run.shuffle, num_workers=run.num_workers)\n",
    "        \n",
    "        network.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                images = batch[0].to(device) # allow to try CUDA\n",
    "                labels = batch[1].to(device) # allow to try CUDA\n",
    "                preds = network(images) # pass batch     \n",
    "                accuracy = (preds.argmax(dim=1).eq(labels).sum().item()) / float(run.batch_size)\n",
    "        print('Test Accuracy of the normalized-dataset model on the 10000 test images: %.2f' % accuracy)\n",
    "#         params['test_accuracy'] = accuracy # Just write this to another data frame then append it then save\n",
    "        \n",
    "m.save(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a92ea289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>device</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.744353</td>\n",
       "      <td>0.996300</td>\n",
       "      <td>31.787043</td>\n",
       "      <td>131.156647</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.763967</td>\n",
       "      <td>0.995767</td>\n",
       "      <td>33.016057</td>\n",
       "      <td>130.183293</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.922963</td>\n",
       "      <td>0.995017</td>\n",
       "      <td>28.016947</td>\n",
       "      <td>127.987806</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.077831</td>\n",
       "      <td>0.994183</td>\n",
       "      <td>32.442022</td>\n",
       "      <td>96.841218</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.081974</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>27.011807</td>\n",
       "      <td>174.878378</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263599</td>\n",
       "      <td>0.993200</td>\n",
       "      <td>29.295499</td>\n",
       "      <td>99.482012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.481577</td>\n",
       "      <td>0.992417</td>\n",
       "      <td>28.928096</td>\n",
       "      <td>147.617012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.454989</td>\n",
       "      <td>0.991833</td>\n",
       "      <td>33.790269</td>\n",
       "      <td>98.908297</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm_net</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "5    3      2  0.744353  0.996300       31.787043    131.156647  0.01   \n",
       "7    4      2  0.763967  0.995767       33.016057    130.183293  0.01   \n",
       "3    2      2  0.922963  0.995017       28.016947    127.987806  0.01   \n",
       "6    4      1  1.077831  0.994183       32.442022     96.841218  0.01   \n",
       "1    1      2  1.081974  0.993983       27.011807    174.878378  0.01   \n",
       "2    2      1  1.263599  0.993200       29.295499     99.482012  0.01   \n",
       "0    1      1  1.481577  0.992417       28.928096    147.617012  0.01   \n",
       "4    3      1  2.454989  0.991833       33.790269     98.908297  0.01   \n",
       "\n",
       "   batch_size  num_workers  shuffle device    trainset            network  \\\n",
       "5        1000            0     True    cpu      normal  no_batch_norm_net   \n",
       "7        1000            0     True    cpu      normal     batch_norm_net   \n",
       "3        1000            0     True    cpu  not_normal     batch_norm_net   \n",
       "6        1000            0     True    cpu      normal     batch_norm_net   \n",
       "1        1000            0     True    cpu  not_normal  no_batch_norm_net   \n",
       "2        1000            0     True    cpu  not_normal     batch_norm_net   \n",
       "0        1000            0     True    cpu  not_normal  no_batch_norm_net   \n",
       "4        1000            0     True    cpu      normal  no_batch_norm_net   \n",
       "\n",
       "   num_epochs  test_accuracy  \n",
       "5           2              0  \n",
       "7           2              0  \n",
       "3           2              0  \n",
       "6           2              0  \n",
       "1           2              0  \n",
       "2           2              0  \n",
       "0           2              0  \n",
       "4           2              0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort DataFrame by Accuracy\n",
    "pd.DataFrame.from_dict(m.run_data, orient=\"columns\").sort_values(\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7cca6",
   "metadata": {},
   "source": [
    "### Evaluate on Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820931d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
