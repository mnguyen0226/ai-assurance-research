{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d636c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time \n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import simplejson as json\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e871ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e728f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1) # in_channel = 1 = grayscale, hyperparam, hyperparam\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5, stride=1) # we in crease the output channel when have extra conv layers\n",
    "                \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120, bias=True) # we also shrink the number of features to number of class that we have\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features=60, bias=True)\n",
    "        self.out = nn.Linear(in_features = 60, out_features=10, bias=True) \n",
    "        \n",
    "    def forward(self, t):\n",
    "        # input layer\n",
    "        t = t\n",
    "        \n",
    "        # convolution 1, not \n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t) # operation do not use weight, unlike layers\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2) # operation do not use weight, unlike layers\n",
    "        \n",
    "        # convolution 2: => relu => maxpool\n",
    "        t = self.conv2(t)\n",
    "        # WHY do we need these 2 layers?\n",
    "        t = F.relu(t) \n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2) # how to determine these values?\n",
    "        \n",
    "        # Transition from Conv to Linear will require flatten\n",
    "        t = t.reshape(-1, 12*4*4) # 4x4 = shape of reduce image (originally 28x28)\n",
    "        \n",
    "        # linear 1:\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # linear 2:\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # output:\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c6f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        # Build runs for us, based on the params we passed in\n",
    "        Run = namedtuple(\"Run\", params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "            \n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e619dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Manager Class for separating tensorboard code\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "    \n",
    "    def begin_run(self, run, network, loader):\n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f\"-{run}\")\n",
    "        \n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image(\"images\", grid)\n",
    "        self.tb.add_graph(self.network, images)\n",
    "    \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar(\"Loss\", loss, self.epoch_count)\n",
    "        self.tb.add_scalar(\"Accuracy\", accuracy, self.epoch_count)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f\"{name}.grad\", param.grad, self.epoch_count)\n",
    "          \n",
    "        # built pandas to analyze data outside of TB\n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results[\"loss\"] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results[\"epoch duration\"] = epoch_duration\n",
    "        results[\"run duration\"] = run_duration\n",
    "        for k,v in self.run_params._asdict().items(): results[k] = v # allow us to see what results match with what param\n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient=\"columns\")\n",
    "        \n",
    "        # update in ipynb in real time\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "    \n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "    \n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data,\n",
    "            orient=\"columns\"\n",
    "        ).to_csv(f\"{fileName}.csv\") # save in csv\n",
    "        \n",
    "        # to create in tensorboard \n",
    "        with open(f\"{fileName}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87723544",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root=\"./data/FashionMNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([ # convert image to \n",
    "        transforms.ToTensor()\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf30a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [0.01],\n",
    "    batch_size = [1000],\n",
    "#     num_workers = [0,1,2,4,8,16]\n",
    "    shuffle = [True]\n",
    ")\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    network = Network()\n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size=run.batch_size, shuffle = shuffle, num_workers=run.num_workers) # num worker to speed up process for dataloader\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(5):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "            preds = network(images) # pass batch\n",
    "            loss = F.cross_entropy(preds, labels) # calculate loss\n",
    "            optimizer.zero_grad() # zero gradient\n",
    "            loss.backward() # back prop for calculating gradient\n",
    "            optimizer.step() # update weights\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        \n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save(\"results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
